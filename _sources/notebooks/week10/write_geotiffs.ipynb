{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1def6f0b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "(week10:write_geotiff)=\n",
    "# Landsat: Writing the scenes for each season to netcdf files\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook starts with a replay of {ref}`week8:fetch` and extends it by showing how to \n",
    "write the first 5 scenes out as netcdf files that store bands 4,5 and 6 plus the Fmask\n",
    "\n",
    "Starting in section {ref}`sec:week10` we demonstrate how to go through a dataframe a row at a time, fetching\n",
    "the geotiffs with `get_landsat_datasets` and saving them to disk as netcdf files.  We also show\n",
    "how to sort files by date in a list, using a sort key.\n",
    "\n",
    "Edit the variables in {ref}`sec:loop` with your landsat specifics and rerun\n",
    "\n",
    "At the end of a full run 10 year run, you should have about (depending on coverage)\n",
    "40 separate season files in your folder.  If your window is about 230 x 300 pixels each file\n",
    "should take about 0.5 Mbytes, so about 20 Mbytes for the whole folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pathlib  import Path\n",
    "import inspect\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import datetime\n",
    "\n",
    "import rioxarray\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import Point\n",
    "import a301_lib\n",
    "\n",
    "from sat_lib.landsat_read import get_landsat_dataset\n",
    "from rasterio.windows import Window\n",
    "import xarray as xr\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c09046",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Ask for all UBC scenes from 2013 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_lon, the_lat = -123.2460, 49.2606\n",
    "location = Point(the_lon, the_lat)\n",
    "date_range = \"2013-01-01/2022-12-31\"\n",
    "#\n",
    "# filename to save the dataframe for future analysis\n",
    "#\n",
    "csv_filename = a301_lib.data_share / \"pha/landsat/vancouver_search.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the STAC endpoint\n",
    "cmr_api_url = \"https://cmr.earthdata.nasa.gov/stac/LPCLOUD\"\n",
    "client = Client.open(cmr_api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959aa57e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Start the search\n",
    "\n",
    "The client takes the search parameters as the following keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = client.search(\n",
    "    collections=[\"HLSL30.v2.0\"],\n",
    "    intersects=location,\n",
    "    datetime= date_range\n",
    ") \n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdf01f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### get the metadata for search items\n",
    "\n",
    "This search should find 388 scenes that contain UBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = search.get_all_items()\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e5131",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Put the results into a list of scenes\n",
    "\n",
    "In this cell, we go over the properties for each scene\n",
    "and store them in a dict -- converting the datetime\n",
    "(which is retrieved as a string of characters) into\n",
    "a python datetime object using the `str_to_datetime` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "scene_list = []\n",
    "for index, value in enumerate(items):\n",
    "    props = value.properties\n",
    "    the_date = pystac.utils.str_to_datetime(props['datetime'])\n",
    "    scene_dict = dict(scene = index,\n",
    "                      cloud_cover = props['eo:cloud_cover'],\n",
    "                      datetime = the_date \n",
    "                       )\n",
    "    scene_list.append(scene_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c56446",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a65c69",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Creating the dataframe\n",
    "\n",
    "We can make a dataframe from a list of dictionaries, using the `from_records` constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "the_df = pd.DataFrame.from_records(scene_list)\n",
    "the_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d39fe6",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Add seasons and month columns to the clear_df\n",
    "\n",
    "The `make_seasoncol` function finds the season for each scene\n",
    "by using the month number -- January-December are months 1-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36488cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seasoncol(row):\n",
    "    seasons = {'djf':[12,1,2],\n",
    "               'mam':[3,4,5],\n",
    "               'jja':[6,7,8],\n",
    "               'son':[9,10,11]}\n",
    "    for season,months in seasons.items():\n",
    "        month = row['datetime'].month\n",
    "        year = row['datetime'].year\n",
    "        if month in months:\n",
    "            #\n",
    "            # the winter of 2013 begins in\n",
    "            # december 2012.  So the year of the\n",
    "            # scene and the year of the season diverge\n",
    "            #\n",
    "            if month == 12:\n",
    "                row['season_year'] = year + 1\n",
    "            else:\n",
    "                row['season_year'] = year\n",
    "            row['season']=season\n",
    "            row['year']= year\n",
    "            row['month']= month\n",
    "            row['day']= row['datetime'].day\n",
    "    return row\n",
    "\n",
    "new_df = the_df.apply(make_seasoncol,axis=1)\n",
    "new_df = new_df[['scene','cloud_cover','season','year','season_year','month','day']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05019c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Store this full list as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dde02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = a301_lib.data_share / \"pha/landsat/vancouver_search.csv\"\n",
    "new_df.to_csv(csv_filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349ded8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Find the low-cloud scenes\n",
    "\n",
    "We don't have a huge number of scenes, so accept any that have less than 50% cloud cover and hope that UBC isn't under a cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_df = new_df[new_df['cloud_cover'] < 50]\n",
    "len(clear_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d707d3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Separate the seasons with groupby\n",
    "\n",
    "Below we use the pandas groupby operator [https://realpython.com/pandas-groupby/](https://realpython.com/pandas-groupby/)\n",
    "to produce a new set of dataframes that all have the same season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbbc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df = clear_df.groupby(['season_year','season'])\n",
    "season_dict = dict(list(season_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict[(2014,'jja')]['cloud_cover']\n",
    "season_dict[(2014,'jja')].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a30d4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "(sec:week10)=\n",
    "## New for week10: Write one scene for each season\n",
    "Take the code from {ref}`week8:pandas_worksheet` to locate the lowest cloud fraction for each season\n",
    "and save to a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(a_df):\n",
    "    \"\"\"\n",
    "    What does this function do?\n",
    "    \"\"\"\n",
    "    min_row = a_df['cloud_cover'].argmin()\n",
    "    return min_row\n",
    "\n",
    "#\n",
    "# explain this loop\n",
    "#\n",
    "out_list = []\n",
    "for the_key, a_df in season_dict.items():\n",
    "    min_row = find_min(a_df)\n",
    "    min_scene = a_df.iloc[min_row]\n",
    "    the_series = pd.Series(min_scene)\n",
    "    out_list.append(the_series)\n",
    "    \n",
    "new_frame = pd.DataFrame.from_records(out_list, index='scene')\n",
    "season_list = Path() / \"save_seasons.csv\"\n",
    "new_frame.to_csv(season_list)\n",
    "new_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f5426",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "(sec:windowed_write)=\n",
    "### Get the windowed region and write to netcdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db33373",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We can take the code from {ref}`week9:test_dataset` to loop over the rows of the data frame\n",
    "and grab the scenes.  Here's how to do it for the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_dir = a301_lib.data_share / \"pha/landsat/ndvi_geotiffs\"\n",
    "geotiff_dir.mkdir(exist_ok = True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GDAL_HTTP_COOKIEFILE\"] = \"./cookies.txt\"\n",
    "os.environ[\"GDAL_HTTP_COOKIEJAR\"] = \"./cookies.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df0232",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "(sec:loop)=\n",
    "### Loop over each row in the dataframe and write the files\n",
    "\n",
    "Change the `ate, lon, lat and window` for your case and turn\n",
    "`do_write` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_write=False\n",
    "if do_write:\n",
    "    lon, lat  = -123.2460, 49.2606\n",
    "    the_window = Window(col_off=2671, row_off=1352, width=234, height=301)\n",
    "    for row_num in np.arange(5,len(new_frame)):\n",
    "        row = new_frame.iloc[row_num]\n",
    "        year,month,day = row['year'],row['month'],row['day']\n",
    "        the_date = f\"{year:02d}-{month:02d}-{day:02d}\"\n",
    "        the_scene = get_landsat_dataset(the_date, lon, lat, the_window) \n",
    "        file_path = geotiff_dir / f\"landsat_{the_date}_vancouver.nc\"\n",
    "        print(f\"saving to {file_path}\")\n",
    "        the_scene.to_netcdf(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaafbb7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Check: read the datasets back into a dictionary\n",
    "\n",
    "Make sure we can read these back into a dictionary indexed by the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list(geotiff_dir.glob(\"*nc\"))\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = {}\n",
    "for the_file in all_files:\n",
    "    the_ds = rioxarray.open_rasterio(the_file)\n",
    "    the_key = the_ds.day\n",
    "    scene_dict[the_key] = the_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4358fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7ae52",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Sort the keys by date\n",
    "\n",
    "Note that the file listing code doesn't sort the dates in time order\n",
    "We can fix that by defining a sort function that returns a datetime object\n",
    "instead of a character string using [datetime.strptime](https://www.digitalocean.com/community/tutorials/python-string-to-datetime-strptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_sort(x):\n",
    "    the_date = datetime.datetime.strptime(x,\"%Y-%m-%d\")\n",
    "    return the_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c79198",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = list(scene_dict.keys())\n",
    "sorted_keys.sort(key=date_sort)\n",
    "print(sorted_keys)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "numbering": {
   "heading_2": true,
   "heading_3": true
  },
  "source_map": [
   18,
   38,
   60,
   64,
   74,
   80,
   86,
   95,
   101,
   106,
   115,
   129,
   133,
   139,
   145,
   152,
   182,
   186,
   191,
   197,
   202,
   209,
   214,
   219,
   226,
   250,
   255,
   260,
   265,
   271,
   279,
   294,
   300,
   305,
   313,
   317,
   325,
   331
  ],
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}