{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d01272",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "(assign5_solution)=\n",
    "# Assignment 5 Landsat + Marshall Palmer: Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa56aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pathlib  import Path\n",
    "import inspect\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import datetime\n",
    "\n",
    "import rioxarray\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import Point\n",
    "import a301_lib\n",
    "\n",
    "from sat_lib.landsat_read import get_landsat_dataset\n",
    "from rasterio.windows import Window\n",
    "import xarray\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f770ec",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Preliminaries\n",
    "\n",
    "There are two Landsat questions below with cells to place your code and comments.  Before you do that, you'll need to run the {ref}`week10:write_geotiff` notebook\n",
    "to download your windowed landsat scenes into a folder.\n",
    "\n",
    "There is a third question that can be uploaded as a handwritten pdf, with a cell to do the numerical integration## Preliminaries\n",
    "\n",
    "There are two questions below with cells to place your code and comments.  Before you do that, you'll need to run the write_geotiffs.md notebook\n",
    "to download your windowed landsat scenes into a folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e88e7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Headstart: use this function to add masked ndvi to the dataset\n",
    "\n",
    "Since I had some issues writing a robust ndvi function,\n",
    "I've provided a working version in the cell below, with comments explaining the \n",
    "trouble points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ndvi(the_ds):\n",
    "    #\n",
    "    # xarray was unhappy with the extra third dimension\n",
    "    # for the landsat bands:  [1, nrows, ncols]\n",
    "    # so squeeze it out\n",
    "    #\n",
    "    the_ds = the_ds.squeeze()\n",
    "    fmask = the_ds['Fmask']\n",
    "    band_5 = the_ds['B05']*fmask.data\n",
    "    band_4 = the_ds['B04']*fmask.data\n",
    "    ndvi  = (band_5 - band_4)/(band_5 + band_4)\n",
    "    #\n",
    "    # Fmask doesn't find every bad pixel, so go ahead\n",
    "    # and set pixels to np.nan for any ndvi not between 0-1\n",
    "    #\n",
    "    ndvi.data[ndvi.data < 0] = np.nan\n",
    "    ndvi.data[ndvi.data > 1] = np.nan\n",
    "    #\n",
    "    # Make a new dataArray \n",
    "    #\n",
    "    ndvi_array = xarray.DataArray(data = ndvi, dims = [\"y\",\"x\"])\n",
    "    #\n",
    "    # you'll get nan conversion errors unless you specifiy nan as\n",
    "    # your missing value\n",
    "    #\n",
    "    ndvi_array.rio.write_nodata(np.nan, inplace=True)\n",
    "    #\n",
    "    # copy the crs and affine transform from band 4\n",
    "    #\n",
    "    ndvi_array.rio.write_crs(band_4.rio.crs, inplace=True)\n",
    "    ndvi_array.rio.write_transform(band_4.rio.transform(), inplace=True)\n",
    "    #\n",
    "    # add some attributes\n",
    "    #\n",
    "    ndvi_array = ndvi_array.assign_attrs({'day':the_ds.day,\n",
    "                                          'band_name':'ndvi',\n",
    "                                          'history':'written by write_ndvi notebook'})\n",
    "    #\n",
    "    # add the ndvi_array to the dataset and return\n",
    "    #\n",
    "    ndvi_dataset = the_ds.assign(variables = {'ndvi' : ndvi_array})\n",
    "    return ndvi_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6ee91",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Make paths for input and output directories\n",
    "\n",
    "It's a good idea to avoid clobbering your original data.  Since the files aren't huge,\n",
    "it doesn't hurt to add the ndvi to the dataset and then write the new dataset into\n",
    "an output folder, called `out_dir` in the sell below.  You've now got duplicate data for bands 4,5,6, and Fmask, \n",
    "but if you avoid the risk of stepping on your original files.\n",
    "\n",
    "The `in_dir` is the directory holding your 39 downloaded \n",
    "ncfiles  written by `get_landsat_dataset`\n",
    "\n",
    "The `out_dir` is the directory that holds the new nc files\n",
    "that contain the original bands + Fmask and the ndvi dataArray\n",
    "added by calc_ndvi\n",
    "\n",
    "Note that sometimes you'll get permission and dimension errors when you try to overwrite\n",
    "files in `output_dir` -- just delete the folder and rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fa2b4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Write out the ndvi files into a new folder\n",
    "\n",
    "### For Vancouver:\n",
    "\n",
    "Adding some print stastements to the `calc_ndvi` loop shows that there are some problems for the Vancouver scene -- scenes\n",
    "23, 31, 34 and 36 are all uncalibrated, with reflectivities that haven't been scaled to 0-> 1.\n",
    "This shouldn't matter for the ndvi since the constant calibration constant is the same\n",
    "for both Band 4 and Band 5 it will divide out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce20afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# my 39 geotiffs are in the folder \"ndvi_geotiffs\"\n",
    "#\n",
    "in_dir = a301_lib.data_share / \"pha/landsat/ndvi_geotiffs\"\n",
    "#\n",
    "#  I'll write my new datasets to ndvi_geotiffs_output\n",
    "#\n",
    "out_dir = a301_lib.data_share / \"pha/landsat/ndvi_geotiffs_outdir\"\n",
    "in_dir.mkdir(exist_ok = True, parents=True)\n",
    "out_dir.mkdir(exist_ok = True, parents=True)\n",
    "\n",
    "write_it = False\n",
    "if write_it:\n",
    "    in_files = list(in_dir.glob(\"*nc\"))\n",
    "    for count,the_file in enumerate(in_files):\n",
    "        the_ds = rioxarray.open_rasterio(the_file,mode = 'r',mask_and_scale = True)\n",
    "        print(f\"Scene {count}, Date: {the_ds.day}, maximum B05 {np.nanmax(the_ds['B05']):.2f}, cloud cover: {the_ds.cloud_cover}\")\n",
    "        #\n",
    "        # Give the file the same name, but put it in the new folder\n",
    "        #\n",
    "        out_file = out_dir / the_file.name\n",
    "        new_ds = calc_ndvi(the_ds)\n",
    "        new_ds.to_netcdf(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a07d36",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Question 1: Calculate the average ndvi\n",
    "\n",
    "In the cell below write a function takes a dataset with an ndvi array and returns\n",
    "the area average ndvi (consult the docs for `xarray.DataArray.mean`)\n",
    "\n",
    "Use it to loop through all of the datasets and create two dictionaries,\n",
    "one holding the datasets (with the datetime date as the key) and one holding the\n",
    "ndvi average for that dataset (also with the datetime date as the key).\n",
    "\n",
    "Recall from the write_geotiffs notebook that you can convert the `dataset.day` attribute\n",
    "to a datetime object using `strptime`:\n",
    "\n",
    "```python\n",
    "the_date = datetime.datetime.strptime(x,\"%Y-%m-%d\")\n",
    "```\n",
    "\n",
    "Don't forget to open your files with `mask_and_scale = True` so you get floating point\n",
    "values with np.nan for missing pixels\n",
    "\n",
    "```python\n",
    "the_ds = rioxarray.open_rasterio(a_file,'r',mask_and_scale = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5943b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Question 1 answer\n",
    "\n",
    "My approach:  create two empty dictionaries keyed by dates.  The `scene_dict`dictionary holds each scene (so I can check the details, plot the image etc.) and the `ndvi_avg_dict` holds the average ndvi for the scene.  The dates are entered in the order\n",
    "the files are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg(the_ds):\n",
    "    #print(the_ds['ndvi'])\n",
    "    ndvi = the_ds['ndvi'].squeeze()\n",
    "    ndvi_avg = ndvi.mean(dim = ['x','y'])\n",
    "    return ndvi_avg\n",
    "\n",
    "ndvi_files = list(out_dir.glob(\"*.nc\"))\n",
    "scene_dict = {}\n",
    "ndvi_avg_dict = {}\n",
    "for a_file in ndvi_files:\n",
    "    the_ds = rioxarray.open_rasterio(a_file,'r',mask_and_scale = True)\n",
    "    the_avg = calc_avg(the_ds)\n",
    "    the_date = datetime.datetime.strptime(the_ds.day,\"%Y-%m-%d\")\n",
    "    scene_dict[the_date]=the_ds\n",
    "    ndvi_avg_dict[the_date] = the_avg\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndvi_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aabf04",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Question 2: Plot the ndvi time series\n",
    "\n",
    "In the cell below, extract your dates from your ndvi dictionary into a list and sort them.  Then use those dates as\n",
    "keys to loop over your `ndvi_avg_dict` and construct a corresponding list of ndvi values.\n",
    "\n",
    "Plot the ndvi values as a function of date, and comment on what you see:  is there any trend?  Do the peaks\n",
    "and troughs occur when you would expect them to?  Is the seasonal variablity smaller or larger than the\n",
    "annual variablity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83159a57",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Question 2 answer\n",
    "\n",
    "No evidents of a longterm trend. The seasonal variablily is evident, but there are some larger fluctuations in 2014, 2022.\n",
    "In most years the ndvi increases in the spring, summer and even the fall, with winter minimum values as expected, with\n",
    "the exception of 2019. There are two outliers in the summer of 2015 and the winter of 2023 that look like data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# sort the datetimes so the plot values are time-ordered\n",
    "#\n",
    "\n",
    "sorted_dates = list(scene_dict.keys())\n",
    "sorted_dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9927194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# get the average ndvis in ordered by time\n",
    "#\n",
    "the_ndvi = []\n",
    "for key in sorted_dates:\n",
    "    the_ndvi.append(ndvi_avg_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(sorted_dates,the_ndvi)\n",
    "ax.plot(sorted_dates,the_ndvi,'ro')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81eddc4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### The two problem datapoints\n",
    "\n",
    "Look at the ndvi images for winter 2023 and summer 2015 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9cafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scene = sorted_dates[-1]\n",
    "dec_2022 = datetime.datetime(2022, 12, 1, 0, 0)\n",
    "last_ds = scene_dict[dec_2022].squeeze()\n",
    "print(f\"{last_ds.cloud_cover=}\")\n",
    "last_ds['ndvi'].plot.imshow()\n",
    "plt.title('december 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e1e1b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "What's the problem with 2015-07-07?  Compare July 2015 with May 2015 -- it looks like either a cirrus cloud or a cloud shadow went undetected by the\n",
    "cloud cover algorithm and shaded the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee503146",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime(2015, 7, 7, 0, 0)\n",
    "july_2015_ds = scene_dict[date].squeeze()\n",
    "july_2015_ds['ndvi'].plot.imshow()\n",
    "plt.title('july 2015');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b924e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime(2015, 5, 20, 0, 0)\n",
    "may_2015_ds = scene_dict[date].squeeze()\n",
    "may_2015_ds['ndvi'].plot.imshow()\n",
    "plt.title('may 2015');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09aaf7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09fadf",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    " Integrate $Z=\\int D^6 n(D) dD$ on paper, assuming a Marshall Palmer size distribution and show that it integrates to:\n",
    "\n",
    "$$\n",
    "Z \\approx 300 RR^{1.5}\n",
    "$$\n",
    "\n",
    "with Z in $mm^6\\,m^{-3}$ and RR in mm/hr.  It's helpful to know that:\n",
    "\n",
    "$$\n",
    "\\int^\\infty_0 x^n \\exp( -a x) dx = n! / a^{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd4e54",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Question 3 answer\n",
    "\n",
    "\n",
    "$$\n",
    "n(D) = n_0 \\exp(-4.1 RR^{-0.21} D )\n",
    "$$\n",
    "\n",
    "with $n_0=8000$ in units of $m^{-3}\\,mm^{-1}$, D in mm,\n",
    "so that $\\Lambda=4.1 RR^{-0.21}$ has to have units\n",
    "of $mm^{-1}$.\n",
    "\n",
    "If we use this to integrate:\n",
    "\n",
    "$$\n",
    "Z=\\int D^6 n(D) dD\n",
    "$$\n",
    "\n",
    "and use the hint that\n",
    "\n",
    "$$\n",
    "\\int^\\infty_0 x^n \\exp( -a x) dx = n! / a^{n+1}\n",
    "$$\n",
    "\n",
    "with n=6 we get:\n",
    "\n",
    "$$\n",
    "Z=\\frac{n_0\\, 6!}{\\Lambda^7}\n",
    "$$\n",
    "\n",
    "with units of  $m^{-3}\\,mm^{-1}/(mm^{-1})^7=mm^6\\,m^{-3}$ as required.  Since\n",
    "$n_0=8000m^{-3}\\,mm^{-1}$ and 6!=720, the\n",
    "numerical coeficient is `8000x720/(4.1**7)=295.75` and  the final form is:\n",
    "\n",
    "$$\n",
    "Z=296 RR^{1.47}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188a916",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Numerical approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Marshall Palmer distribution\n",
    "#\n",
    "def calc_num_dist(Dvals,RR,n0=8000):\n",
    "    the_dist = n0*np.exp(-4.1*RR**(-0.21)*Dvals)\n",
    "    return the_dist\n",
    "\n",
    "Dvals = np.linspace(0.01,5,1000)\n",
    "dD = np.diff(Dvals)\n",
    "#\n",
    "# need the midpoint diameters for the rectangular integration\n",
    "#\n",
    "Dmid = (Dvals[1:] + Dvals[0:-1])/2.\n",
    "\n",
    "#\n",
    "# loop over 100 rain rates\n",
    "#\n",
    "RRvals = np.linspace(0.1,5,100)\n",
    "\n",
    "#\n",
    "# Brute force integration\n",
    "#\n",
    "Zvals = []\n",
    "for the_RR in RRvals:\n",
    "    num_dist = calc_num_dist(Dvals,the_RR)\n",
    "    bin_heights = (num_dist[1:] + num_dist[0:-1])/2.\n",
    "    theZ = np.sum(Dmid**6.*bin_heights*dD)\n",
    "    Zvals.append(theZ)\n",
    "    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(RRvals,Zvals,'ro',alpha=0.4,label='numeric')\n",
    "Z_math = 296*RRvals**1.47\n",
    "ax.plot(RRvals,Z_math,'bx',label=\"math\")\n",
    "ax.set(xlabel=\"RR (mm/hour)\",ylabel=\"Z mm^6/m^3\")\n",
    "ax.grid(True)\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573692db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115dbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "numbering": {
   "heading_2": true,
   "heading_3": true
  },
  "source_map": [
   19,
   24,
   46,
   58,
   66,
   111,
   130,
   141,
   167,
   192,
   199,
   219,
   223,
   234,
   242,
   251,
   260,
   267,
   273,
   277,
   286,
   291,
   298,
   305,
   309,
   323,
   362,
   366,
   405,
   409
  ],
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}